{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9gpi-r5in7K"
      },
      "source": [
        "# Course 3: Sentiment Analysis using Naive Bayes\n",
        "In this tutorial you'll learn how to build a sentiment analysis model using Naive Bayes:\n",
        "\n",
        "* Train a naive bayes model on a sentiment analysis task\n",
        "* Test using your model\n",
        "* Compute ratios of positive words to negative words\n",
        "* Error analysis\n",
        "* Predict on your own text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_6gEwMMin7L"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [Importing Functions and Data](#0)\n",
        "- [1 - Process the Data](#1)\n",
        "- [2 - Train your Model using Naive Bayes](#2)\n",
        "- [3 - Test your Naive Bayes](#3)\n",
        "- [4 - Filter words by Ratio of Positive to Negative Counts](#4)\n",
        "- [5 - Error Analysis](#5)\n",
        "- [6 - Predict with your own Text](#6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sG2fSFgin7M"
      },
      "source": [
        "<a name='0'></a>\n",
        "## Import Libraries and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liS4XQoXin7M",
        "outputId": "5c42a5f6-ce23-46ca-fd5e-e45cbf5acf1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pdb\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from os import getcwd\n",
        "nltk.download()\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "gU42cDC5in7N",
        "outputId": "7d88f472-0bc5-4c4b-b430-76758824e25e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e92c5b3-670b-499d-8618-d3d37e29aeb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e92c5b3-670b-499d-8618-d3d37e29aeb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e92c5b3-670b-499d-8618-d3d37e29aeb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e92c5b3-670b-499d-8618-d3d37e29aeb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3684a25a-d95c-4f17-8b57-de424995d681\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3684a25a-d95c-4f17-8b57-de424995d681')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3684a25a-d95c-4f17-8b57-de424995d681 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 49999,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49580,\n        \"samples\": [\n          \"This movie was a modern day scarface.It had me on my toes.This movie is one of those rare epic films that makes you want a sequel.I especially liked Damian Chapa his performance deserved an academy award,which he deserved for his performance in blood in blood out.The only thing I didn't like was the behind the scenes because it didn't show the intensity that the movie had,and i would have like to have seen less narrated scenes.But the movie was great and it is in my top ten movies of all time.Plus the acting was great there wasn't a bad scene in the movie,I loved it ,Jennifer Tilly was perfect as well as all of the cast.I can't see how anyone wouldn't like this movie it was a great.Definitely a must see.\",\n          \"This is probably one of the best French movies I had seen in a very long time! This \\\"pastiche\\\" or parody of spy movies is very well made and is going to make you laugh from the beginning to the end. Some references to today's world are very subtle. The whole Maroccan context of the movie is to be understood in light of today's French culture/environment. That said, all the jokes and - seemingly - shocking remarks that could have been understood as such because of this context, are permitted and accepted because this is a parody. <br /><br />I was told by my sisters who had already seen this movie that I should go too and assured me that I was going to have a great time, and indeed I had! If you liked the old 007 movies with Sean Connery and also like movies like Airplane or Hot Shots, you will be delighted. I just hope this movie is released on DVD in the US... Wait and see.\",\n          \"\\\"Giant\\\" is one of the most boring, overly-long Hollywood contraptions ever. Many scenes seem utterly fake and without energy. Rock Hudson, Elizabeth Taylor, and James Dean are wasted in this big Hollywood production. A central notion to this movie, that a rancher would ever resist drilling for oil on his land, is absurd, and I know this because I'm from Houston. A couple of scenes, especially Dean serving Taylor coffee, redeem this otherwise boring film. For a much more accurate and interesting depiction about how modernism changed the ranches in Texas, see \\\"Hud\\\" (one of Paul Newman's great performances) or \\\"The Last Picture Show.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df = pd.read_csv('/content/IMDB.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbAL81I_in7N"
      },
      "source": [
        "### Prepare the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwPP-8Tzin7N"
      },
      "source": [
        "* Train set 80% and test set 20%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyz7ZseMin7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d79771-741c-4791-8e18-7f98b43312d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train X shape: (39999,)\n",
            "Test X shape: (10000,)\n",
            "Train Y shape: (39999, 1)\n",
            "Test Y shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Encode labels: pos=1, neg=0\n",
        "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Shuffle data\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split data\n",
        "train_x, test_x, train_y, test_y = train_test_split(\n",
        "    df['review'], df['label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "train_x = np.array(train_x.tolist())\n",
        "test_x = np.array(test_x.tolist())\n",
        "train_y = np.array(train_y).reshape(-1, 1)\n",
        "test_y = np.array(test_y).reshape(-1, 1)\n",
        "\n",
        "print(\"Train X shape:\", train_x.shape)\n",
        "print(\"Test X shape:\", test_x.shape)\n",
        "\n",
        "\n",
        "print(\"Train Y shape:\", train_y.shape)\n",
        "print(\"Test Y shape:\", test_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp13616iin7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73dca893-ece0-408b-8cbd-0e05f690d107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['I haven\\'t seen this film since it came out in the mid 70s, but I do recall it as being a very realistic portrayal of the music business ( right up there with Paul Simons \"One Trick Pony \" ..another vastly underrated film IMO )<br /><br />Harvey Keitel does an excellent job as a producer caught between the music he believes in , and the commercial \"tripe\" the record company \"suits\" want him to work with.<br /><br />Since I spent my entire career in the music business as a composer /arranger /producer, I can really vouch for the verisimilitude this film possesses. <br /><br />If it should ever come out on DVD uncut, I\\'d buy it!',\n",
              "       \"I recently rented this movie as part of a nostalgic phase I'm going through. I was born in 1980, and so film from mid-80s to mid-90s has quite an important place in my growing up.<br /><br />This particular movie was one of my favourites, and so I was thrilled when it became available in the UK. It hasn't become worse with time, it is still a great fun film, with plenty of excitement in its own way. Sure, it pales in the shadow of bigger, larger budget films, but don't let that stop you enjoying this.<br /><br />Worth a rent, or even a purchase at the discount prices you'll find it for.\",\n",
              "       \"How do I describe the horrors?!!! First, some points: First, this review should be taken with a grain of salt -- I saw this over 20 years ago, when I was a boy, at the Museum of Modern Art in New York City.<br /><br />Secondly, I am giving away some scenes and plot points. However, it does not have much of a plot.<br /><br />Finally, I don't enjoy these type of art films anyway.<br /><br />This film was directed by proto-auteur Luis Bunuel. He was a surrealist and dadaist. These were modernist themes or movements popular critically in the 1920's and early 1930's. Surealism was the school of art that made things hyper-real, yet often had Freudian symbolism. Dadaism is based on what is supposedly the first word made by an infant -- Dada, or father.<br /><br />Made in black and white, it was also made by a band of communists (or as they preferred the term, socialists). Bunuel and his group of fellow film-makers and artistes had been working on a number of symbolic ideas and issues in Spain and France between the world wars.<br /><br />Dadaism and surrealism influenced a lot of artists -- The Police (Doo doo doo da), poet Arthur Rambaud, Edvard Munch (The Scream), Rene Magritte (floating hats in space), Salvador Dali (melting clocks), and even Hitchcock (Psycho). No Norman Rockwell.<br /><br />Here's what I recall most about this film: a girl meets up with a cow; her eye gets slashed by a razor; clownish men cavort in a meadow. There is not, as I said, much of a plot, but then again, that must be the point.<br /><br />This was attacked as porn back then, and would be again today. One of the trade-marks of surrealism is a significant anti-feminism.\",\n",
              "       ...,\n",
              "       'We just saw this movie in Austin Texas at the Alamo South Lamar yesterday afternoon. It had me laughing out loud many times! The scene about Albert Einstein\\'s thoughts on humanity hit me over and over and I couldn\\'t stop laughing. It\\'s too bad it\\'s not in more theaters, I know a lot of friends that are dieing to see this movie! \"Welcome to Costco, I love you.\" ... great work to all involved! Also, if you see it, make sure to stay until the end of the credits as well! I\\'m going to take my family to see it again this weekend for sure! If you\\'re a fan of OFFICE SPACE and BEAVIS AND BUTTHEAD then you have to go see this movie. It\\'s a classic and no one knows that it\\'s out! So if you\\'re in the mood to see something funny this weekend, definitely check it out.',\n",
              "       \"This is a catastrophe movie set in London . Starting multiple hurricane,superstorm and tornadoes on Scotland are displaced towards East , downing England coast and later the South. After several hours of heavy rainful , the London barrier above Thames is short from running over, and it paves the way for disaster. Then a colossal tidal-wave travel relentless down East causing devastation and lives of millions of Londoners are in danger. At the center of the story is a climatologist(Tom Courtenay) a climatologist who tries to save London from the effects of giant wave , trying to convince the authorities that the town dike was unsafe, furthermore a marine engineer (Robert Carlyle) and his ex-wife Samantha(Jessalyn Gilsig) . They are trapped into the barrier and dropped to sea .Meantime the secret government agency HQ ruled by Nash(Joanne Whalley) under direct orders of deputy Minister(David Suchet) attempt to control many displaced and avoid more dead, approximately 200.000. They have a little time to save London from total catastrophe.<br /><br />Perfectly acceptable drama-disaster with alright acting. Magnificent Tom Courtenay as a climatologist who predicts catastrophe and excellent Robert Carlyle and Jessalyn Gilsig as ex-matrimony rekindling their love. The movie packs impressive flood scenes brought to life by the breathtaking computer generator special effects, better than the classic of the 70s , such as 'Earthquake, Inferno Towering' and similarly to 'Armaguedon and Day after tomorrow'. Although isn't a clear denounce, we know that the flood is caused by the greenhouse effect and global warming which originates the ozone hole. The motion picture is well directed by Tony Mitchell. I would recommend this movie to people who like disaster movies. Another adaptations about floods, are the following : 'Flood(1976)'directed by Earl Bellamy with Robert Culp and Barbara Hershey; 'Hard rain(1998)' directed by Mikael Salomon with Morgan Freeman and Christian Slater; ' Flood : a river's rampage(1979)' directed by Bruce Pittman with Richard Thomas\",\n",
              "       \"This movie sucked. The acting sucked, the script sucked, and the movie overall sucked. There were two threads in the movie that were not developed and the viewer had to do a bit of work to figure out what was happening.<br /><br />I'm not saying that it needs to be spelled out, but you suddenly find things happening and being said as if you have the slightest clue as to what they are. Examples:<br /><br />The heroine's negative comments about the hero. The audience is never shown how she even knows anything about the guy and how he is tied into her fiance's death. The viewer has minimal exposure to the guy's death as well.<br /><br />Also, all of a sudden there is a scene with a bunch of guys loading up and cocking machine guns and that is all you see before cutting back to the other scenes. No explanation what-so-ever about the guns and the folks with them.<br /><br />We gave it a 3 because we didn't feel like we wanted our time back. It was fun to bad-mouth the movie while watching it, so it at least gave us a bit of entertainment. ;-)\"],\n",
              "      dtype='<U13704')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "train_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTYoXi9yin7O",
        "outputId": "5295052c-f465-4720-c7e9-e4c9529ce6a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXnaQ-7Gin7O"
      },
      "source": [
        "* Create the function for processing the string/text:\n",
        "    - tokenization.\n",
        "    - remove stop words.\n",
        "    - apply stemming.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ylf4Zmxjin7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e76e0c-29db-4b60-f7a6-0be6a7d0e5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Preprocessing function\n",
        "def process_text(text):\n",
        "    \"\"\"Clean and preprocess IMDB review text.\"\"\"\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove hyperlinks\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "\n",
        "    # Remove HTML tags (like <br />)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Tokenize\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    # Remove stopwords and apply stemming\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    cleaned = [\n",
        "        stemmer.stem(word)\n",
        "        for word in tokens\n",
        "        if word not in stop_words and word.isalpha()\n",
        "    ]\n",
        "\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_text(train_x[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Vtg3EBsjoz",
        "outputId": "31850d96-7d5a-48ae-b580-850972b919d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['spoiler',\n",
              " 'film',\n",
              " 'noth',\n",
              " 'could',\n",
              " 'written',\n",
              " 'could',\n",
              " 'make',\n",
              " 'wors',\n",
              " 'dictionari',\n",
              " 'definit',\n",
              " 'pueril',\n",
              " 'read',\n",
              " 'sex',\n",
              " 'live',\n",
              " 'potato',\n",
              " 'men',\n",
              " 'unless',\n",
              " 'like',\n",
              " 'dog',\n",
              " 'poo',\n",
              " 'mucou',\n",
              " 'case',\n",
              " 'film',\n",
              " 'see',\n",
              " 'johnni',\n",
              " 'vega',\n",
              " 'et',\n",
              " 'think']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_clean = [' '.join(process_text(text)) for text in train_x]\n",
        "test_x_clean = [' '.join(process_text(text)) for text in test_x]"
      ],
      "metadata": {
        "id": "nPTXES7DspAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOFPfkiRin7P"
      },
      "source": [
        "* Create the frequency dictionary function.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmfV4y3oin7P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def build_freqs(texts, labels):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        texts  - a list/array of review texts\n",
        "        labels - a 2D numpy array of labels (0 or 1)\n",
        "    Output:\n",
        "        freqs  - dictionary of (word, label) → frequency\n",
        "    \"\"\"\n",
        "    # Flatten labels to 1D list\n",
        "    labels_list = np.squeeze(labels).tolist()\n",
        "\n",
        "    freqs = {}\n",
        "\n",
        "    # Loop through each (label, text) pair\n",
        "    for y, text in zip(labels_list, texts):\n",
        "        for word in process_text(text):\n",
        "            pair = (word, y)\n",
        "            freqs[pair] = freqs.get(pair, 0) + 1\n",
        "\n",
        "    return freqs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O10NsAkin7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4a027a-5349-4ddb-d2ba-23864765e0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of freqs: <class 'dict'>\n",
            "Number of (word, label) pairs: 184828\n"
          ]
        }
      ],
      "source": [
        "# create frequency dictionary\n",
        "freqs = build_freqs(train_x, train_y)\n",
        "\n",
        "print(\"Type of freqs:\", type(freqs))\n",
        "print(\"Number of (word, label) pairs:\", len(freqs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twOHAiJ9in7P"
      },
      "source": [
        "### Process Text\n",
        "The given function 'process_text' tokenizes the sentence into individual words, removes stop words and applies stemming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQYG3AtXin7Q",
        "outputId": "e7a1aeea-763f-420d-f8b0-c0a25ebfe2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original IMDB review:\n",
            " I haven't seen this film since it came out in the mid 70s, but I do recall it as being a very realistic portrayal of the music business ( right up there with Paul Simons \"One Trick Pony \" ..another vastly underrated film IMO )<br /><br />Harvey Keitel does an excellent job as a producer caught between the music he believes in , and the commercial \"tripe\" the record company \"suits\" want him to work with.<br /><br />Since I spent my entire career in the music business as a composer /arranger /producer, I can really vouch for the verisimilitude this film possesses. <br /><br />If it should ever come out on DVD uncut, I'd buy it!\n",
            "\n",
            "Processed version of the review:\n",
            " ['havent', 'seen', 'film', 'sinc', 'came', 'mid', 'recal', 'realist', 'portray', 'music', 'busi', 'right', 'paul', 'simon', 'one', 'trick', 'poni', 'anoth', 'vastli', 'underr', 'film', 'imo', 'harvey', 'keitel', 'excel', 'job', 'produc', 'caught', 'music', 'believ', 'commerci', 'tripe', 'record', 'compani', 'suit', 'want', 'work', 'withsinc', 'spent', 'entir', 'career', 'music', 'busi', 'compos', 'arrang', 'produc', 'realli', 'vouch', 'verisimilitud', 'film', 'possess', 'ever', 'come', 'dvd', 'uncut', 'id', 'buy']\n"
          ]
        }
      ],
      "source": [
        "# test the function below\n",
        "print('Original IMDB review:\\n', train_x[0])\n",
        "print('\\nProcessed version of the review:\\n', process_text(train_x[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20XkeBX-in7Q"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Train your Model using Naive Bayes\n",
        "\n",
        "Naive bayes is an algorithm that could be used for sentiment analysis. It takes a short time to train and also has a short prediction time.\n",
        "\n",
        "#### So how do you train a Naive Bayes classifier?\n",
        "- The first part of training a naive bayes classifier is to identify the number of classes that you have.\n",
        "- You will create a probability for each class.\n",
        "$P(D_{pos})$ is the probability that the document is positive.\n",
        "$P(D_{neg})$ is the probability that the document is negative.\n",
        "Use the formulas as follows and store the values in a dictionary:\n",
        "\n",
        "$$P(D_{pos}) = \\frac{D_{pos}}{D}\\tag{1}$$\n",
        "\n",
        "$$P(D_{neg}) = \\frac{D_{neg}}{D}\\tag{2}$$\n",
        "\n",
        "Where $D$ is the total number of documents, or tweets in this case, $D_{pos}$ is the total number of positive tweets and $D_{neg}$ is the total number of negative tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4IPh39bin7Q"
      },
      "source": [
        "#### Prior and Logprior\n",
        "\n",
        "The prior probability represents the underlying probability in the target population that a tweet is positive versus negative.  In other words, if we had no specific information and blindly picked a tweet out of the population set, what is the probability that it will be positive versus that it will be negative? That is the \"prior\".\n",
        "\n",
        "The prior is the ratio of the probabilities $\\frac{P(D_{pos})}{P(D_{neg})}$.\n",
        "We can take the log of the prior to rescale it, and we'll call this the logprior\n",
        "\n",
        "$$\\text{logprior} = log \\left( \\frac{P(D_{pos})}{P(D_{neg})} \\right) = log \\left( \\frac{D_{pos}}{D_{neg}} \\right)$$.\n",
        "\n",
        "Note that $log(\\frac{A}{B})$ is the same as $log(A) - log(B)$.  So the logprior can also be calculated as the difference between two logs:\n",
        "\n",
        "$$\\text{logprior} = \\log (P(D_{pos})) - \\log (P(D_{neg})) = \\log (D_{pos}) - \\log (D_{neg})\\tag{3}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjHrdDWuin7Q"
      },
      "source": [
        "#### Positive and Negative Probability of a Word\n",
        "To compute the positive probability and the negative probability for a specific word in the vocabulary, we'll use the following inputs:\n",
        "\n",
        "- $freq_{pos}$ and $freq_{neg}$ are the frequencies of that specific word in the positive or negative class. In other words, the positive frequency of a word is the number of times the word is counted with the label of 1.\n",
        "- $N_{pos}$ and $N_{neg}$ are the total number of positive and negative words for all documents (for all tweets), respectively.\n",
        "- $V$ is the number of unique words in the entire set of documents, for all classes, whether positive or negative.\n",
        "\n",
        "We'll use these to compute the positive and negative probability for a specific word using this formula:\n",
        "\n",
        "$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V}\\tag{4} $$\n",
        "$$ P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V}\\tag{5} $$\n",
        "\n",
        "Notice that we add the \"+1\" in the numerator for additive smoothing.  This [wiki article](https://en.wikipedia.org/wiki/Additive_smoothing) explains more about additive smoothing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91yZRVFGin7Q"
      },
      "source": [
        "#### Log likelihood\n",
        "To compute the loglikelihood of that very same word, we can implement the following equations:\n",
        "\n",
        "$$\\text{loglikelihood} = \\log \\left(\\frac{P(W_{pos})}{P(W_{neg})} \\right)\\tag{6}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRthr9Fvin7Q"
      },
      "outputs": [],
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    '''\n",
        "    Inputs:\n",
        "        freqs: dictionary from (word, label)\n",
        "        train_x: a list of sentences\n",
        "        train_y: a list of labels (0,1)\n",
        "    Outputs:\n",
        "        logprior: the log prior\n",
        "        loglikelihood: the log likelihood of you Naive bayes equation\n",
        "    '''\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "    # calculate V, the number of unique words in the vocabulary\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # calculate N_pos, N_neg, V_pos, V_neg\n",
        "    N_pos = N_neg = V_pos=V_neg=0\n",
        "    for pair in freqs.keys():\n",
        "        # if the label is positive (greater than zero)\n",
        "        if pair[1] > 0:\n",
        "\n",
        "            # Increment the number of positive words by the count for this (word, label) pair\n",
        "            N_pos += freqs[pair]\n",
        "            V_pos += 1\n",
        "        # else, the label is negative\n",
        "        else:\n",
        "\n",
        "            # increment the number of negative words by the count for this (word,label) pair\n",
        "            N_neg += freqs[pair]\n",
        "            V_neg += 1\n",
        "    # Calculate D, the number of documents\n",
        "    D = train_y.shape[0]\n",
        "\n",
        "    # Calculate D_pos, the number of positive documents\n",
        "    D_pos = train_y[train_y == 1].shape[0]\n",
        "\n",
        "    # Calculate D_neg, the number of negative documents\n",
        "    D_neg = train_y[train_y == 0].shape[0]\n",
        "\n",
        "    # Calculate logprior\n",
        "    logprior = np.log(D_pos / D) - np.log(D_neg / D)\n",
        "\n",
        "    # For each word in the vocabulary...\n",
        "    for word in vocab:\n",
        "        # get the positive and negative frequency of the word\n",
        "        freq_pos = freqs.get((word, 1), 0)\n",
        "        freq_neg = freqs.get((word, 0), 0)\n",
        "\n",
        "        # calculate the probability that each word is positive, and negative\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "        # calculate the log likelihood of the word\n",
        "        loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
        "\n",
        "    return logprior, loglikelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJS1Vraein7Q",
        "outputId": "fde0458f-c234-478f-b46c-4a6b1d494187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0017500441977420511\n",
            "149527\n"
          ]
        }
      ],
      "source": [
        "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
        "print(logprior)\n",
        "print(len(loglikelihood))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjmrNniJin7R"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Test your Naive Bayes\n",
        "\n",
        "Now that we have the `logprior` and `loglikelihood`, we can test the naive bayes function by making predicting on some text!\n",
        "\n",
        "<a name='ex-3'></a>\n",
        "### Exercise 3 - naive_bayes_predict\n",
        "Implement `naive_bayes_predict`.\n",
        "\n",
        "**Instructions**:\n",
        "Implement the `naive_bayes_predict` function to make predictions on text.\n",
        "* The function takes in the `text`, `logprior`, `loglikelihood`.\n",
        "* It returns the probability that the review belongs to the positive or negative class.\n",
        "* For each review, sum up loglikelihoods of each word in the review.\n",
        "* Also add the logprior to this sum to get the predicted sentiment of that review.\n",
        "\n",
        "$$ p = logprior + \\sum_i^N (loglikelihood_i)$$\n",
        "\n",
        "#### Note\n",
        "Note we calculate the prior from the training data, and that the training data is evenly split between positive and negative labels (4000 positive and 4000 negative reviews).  This means that the ratio of positive to negative 1, and the logprior is 0.\n",
        "\n",
        "The value of 0.0 means that when we add the logprior to the log likelihood, we're just adding zero to the log likelihood.  However, please remember to include the logprior, because whenever the data is not perfectly balanced, the logprior will be a non-zero value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8988-e7in7R"
      },
      "outputs": [],
      "source": [
        "def naive_bayes_predict(sentence, logprior, loglikelihood):\n",
        "    '''\n",
        "    Inputs:\n",
        "        sentence: a string\n",
        "        logprior: a number\n",
        "        loglikelihood: a dictionary of words mapping to numbers\n",
        "    Outputs:\n",
        "        p: the sum of all the logliklihoods of each word in the tweet (if found in the dictionary) + logprior (a number)\n",
        "\n",
        "    '''\n",
        "    # process the sentence to get a list of words\n",
        "    word_l = process_text(sentence)\n",
        "    # initialize probability to zero\n",
        "    p = 0\n",
        "    # add the logprior\n",
        "    p += logprior\n",
        "    for word in word_l:\n",
        "        # check if the word exists in the loglikelihood dictionary\n",
        "        if word in loglikelihood:\n",
        "            # add the log likelihood of that word to the probability\n",
        "            p += loglikelihood[word]\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjGJLDCein7R",
        "outputId": "4ba972ab-8ecc-4c45-806a-7e89218dc6ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected output is 2.6758019020181307\n"
          ]
        }
      ],
      "source": [
        "my_review = 'The performances were outstanding and the story kept me hooked until the very end.'\n",
        "p = naive_bayes_predict(my_review, logprior, loglikelihood)\n",
        "print('The expected output is', p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJjFHCAain7R",
        "outputId": "1a493e0b-37f5-4e2e-d704-c6bf921a9d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected output is -3.9698196122782514\n"
          ]
        }
      ],
      "source": [
        "my_review = 'The plot was a mess and the acting felt forced and unnatural.'\n",
        "p = naive_bayes_predict(my_review, logprior, loglikelihood)\n",
        "print('The expected output is', p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_nsR4rcin7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4bf9a0-8cb0-468c-aeee-213d90cbebfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy = 0.8466\n"
          ]
        }
      ],
      "source": [
        "# Clean the test data\n",
        "test_x_clean = [' '.join(process_text(text)) for text in test_x]\n",
        "\n",
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    accuracy = 0\n",
        "    y_hats = []\n",
        "\n",
        "    for s in test_x:\n",
        "        # if the prediction is > 0\n",
        "        if naive_bayes_predict(s, logprior, loglikelihood) > 0:\n",
        "            # the predicted class is 1\n",
        "            y_hat_i = 1\n",
        "        else:\n",
        "            # otherwise the predicted class is 0\n",
        "            y_hat_i = 0\n",
        "\n",
        "        # Store prediction\n",
        "        y_hats.append(y_hat_i)\n",
        "\n",
        "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
        "    error = np.mean(np.abs(np.asarray(y_hats) - np.squeeze(test_y)))\n",
        "\n",
        "    #  Accuracy is 1 minus the error\n",
        "    accuracy = 1 - error\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "print(\"Naive Bayes accuracy = %0.4f\" %\n",
        "      test_naive_bayes(test_x_clean, test_y, logprior, loglikelihood))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK4oshCsin7R"
      },
      "source": [
        "<a name='4'></a>\n",
        "## 4 - Filter words by Ratio of Positive to Negative Counts\n",
        "\n",
        "- Some words have more positive counts than others, and can be considered \"more positive\".  Likewise, some words can be considered more negative than others.\n",
        "- One way for us to define the level of positiveness or negativeness, without calculating the log likelihood, is to compare the positive to negative frequency of the word.\n",
        "    - Note that we can also use the log likelihood calculations to compare relative positivity or negativity of words.\n",
        "- We can calculate the ratio of positive to negative frequencies of a word.\n",
        "- Once we're able to calculate these ratios, we can also filter a subset of words that have a minimum ratio of positivity / negativity or higher.\n",
        "- Similarly, we can also filter a subset of words that have a maximum ratio of positivity / negativity or lower (words that are at least as negative, or even more negative than a given threshold).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmuSCaKXin7R"
      },
      "outputs": [],
      "source": [
        "def get_ratio(freqs, word):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary containing the words\n",
        "\n",
        "    Output: a dictionary with keys 'positive', 'negative', and 'ratio'.\n",
        "        Example: {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
        "    '''\n",
        "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
        "\n",
        "    # use lookup() to find positive counts for the word (denoted by the integer 1)\n",
        "    pos_neg_ratio['positive'] = check_freq(freqs, word, 1)\n",
        "\n",
        "    # use lookup() to find negative counts for the word (denoted by integer 0)\n",
        "    pos_neg_ratio['negative'] = check_freq(freqs, word, 0)\n",
        "\n",
        "    # calculate the ratio of positive to negative counts for the word\n",
        "    pos_neg_ratio['ratio'] = (pos_neg_ratio['positive'] + 1) / (pos_neg_ratio['negative'] + 1)\n",
        "\n",
        "    return pos_neg_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDNAjmvGin7R",
        "outputId": "f4c1bf66-064d-4600-a967-cf2ef80d9532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'positive': 11666, 'negative': 11530, 'ratio': 1.0117942936432227}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "def check_freq(freqs, word, label):\n",
        "\n",
        "    return freqs.get((word, label), 0)\n",
        "\n",
        "get_ratio(freqs, 'good')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaPiUroWin7R",
        "outputId": "31d1af2e-7daa-4e16-8638-93d7441373d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'positive': 1034, 'negative': 582, 'ratio': 1.7753001715265866}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "get_ratio(freqs, 'happi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlVd5gF-in7S"
      },
      "source": [
        "<a name='5'></a>\n",
        "## 5 - Predict with your own text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fciSUaYCin7S",
        "outputId": "04b6b136-51c4-4079-d6a9-90a13f9e2f60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction score: -3.2255816467275102\n",
            "Negative sentiment\n"
          ]
        }
      ],
      "source": [
        "#my_text = \"The story was powerful and the acting was absolutely brilliant.\"\n",
        "my_text = \"The plot was confusing and the dialogue felt flat and emotionless.\"\n",
        "\n",
        "\n",
        "# Predict sentiment\n",
        "p = naive_bayes_predict(my_text, logprior, loglikelihood)\n",
        "print(\"Prediction score:\", p)\n",
        "\n",
        "# Classify\n",
        "if p > 0:\n",
        "    print('Positive sentiment')\n",
        "else:\n",
        "    print('Negative sentiment')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}